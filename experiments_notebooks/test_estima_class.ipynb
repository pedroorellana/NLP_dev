{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so | _pywrap_tensorflow_internal\n",
      "/root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/lite/toco/python/_tensorflow_wrap_toco.so | _tensorflow_wrap_toco\n"
     ]
    }
   ],
   "source": [
    "# Utils\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "#import _pickle as pickle\n",
    "import pickle\n",
    "import re, sys, unidecode\n",
    "#import unidecode\n",
    "\n",
    "\n",
    "# Representation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import scikitplot.plotters as skplt\n",
    "\n",
    "import wordbatch\n",
    "from wordbatch.extractors import WordBag, WordHash\n",
    "from wordbatch.models import FTRL\n",
    "\n",
    "from tensorflow.contrib.learn import DNNClassifier\n",
    "from tensorflow.contrib.learn import DNNEstimator\n",
    "#from tecnosmartlib import DataObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.style.use('fivethirtyeight')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoticias = pd.read_pickle(\"dfNoticias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre procesing\n",
    "\n",
    "Cleaning data, select clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting useful information...done.\n"
     ]
    }
   ],
   "source": [
    "print('Selecting useful information...', end='')\n",
    "_map = {}\n",
    "_map[\"Cuerpo\"] = []\n",
    "_map[\"Seccion\"] = []\n",
    "_map[\"Seccion2\"] = []\n",
    "_map[\"Seccion3\"] = []\n",
    "\n",
    "count = 0\n",
    "for index, row in dfNoticias.iterrows():\n",
    "    if (row[\"Seccion_1\"] != None and row[\"Cuerpo\"] != None):\n",
    "        _map[\"Cuerpo\"].append(row[\"Cuerpo\"]) \n",
    "        _map[\"Seccion\"].append(row[\"Seccion_1\"])\n",
    "        if ( row[\"Seccion_2\"] != None ):\n",
    "            _map[\"Seccion2\"].append(row[\"Seccion_2\"])\n",
    "        else:\n",
    "            _map[\"Seccion2\"].append(row[\"Seccion_1\"])\n",
    "        \n",
    "        if ( row[\"Seccion_3\"] != None ):\n",
    "            _map[\"Seccion3\"].append(row[\"Seccion_3\"])\n",
    "        else:\n",
    "            _map[\"Seccion3\"].append(row[\"Seccion_1\"])\n",
    "        \n",
    "        \n",
    "        if row[\"Seccion_1\"] == row[\"Seccion_2\"] and row[\"Seccion_2\"] == row[\"Seccion_3\"]:\n",
    "            count += 1\n",
    "        if row[\"Seccion_1\"] == row[\"Seccion_2\"] and row[\"Seccion_3\"] == None:\n",
    "            count += 1\n",
    "        if row[\"Seccion_1\"] == row[\"Seccion_3\"] and row[\"Seccion_2\"] == None:  \n",
    "            count += 1 \n",
    "        if row[\"Seccion_2\"] == None and row[\"Seccion_3\"] == None:\n",
    "            count += 1\n",
    "print('done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data before dropping duplicates: 250339\n",
      "Number of data after dropping duplicates : 238918\n",
      "\n",
      "Number of duplicated data : 11421\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(_map)\n",
    "numberOfDuplicates = df.shape[0]\n",
    "print('Number of data before dropping duplicates: {}'.format(df.shape[0]))\n",
    "df = df.drop_duplicates(inplace= False)\n",
    "df.reset_index(drop=True, inplace= True)\n",
    "numberOfDuplicates -= df.shape[0]\n",
    "print('Number of data after dropping duplicates : {}'.format(df.shape[0]))\n",
    "print('\\nNumber of duplicated data : {}'.format(numberOfDuplicates))\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 238918\n"
     ]
    }
   ],
   "source": [
    "X_untransformed = df['Cuerpo'].reset_index(drop=True)\n",
    "y_untransformed = df['Seccion'].reset_index(drop=True)\n",
    "\n",
    "y2_untransformed = df['Seccion2'].reset_index(drop=True)\n",
    "y3_untransformed = df['Seccion3'].reset_index(drop=True)\n",
    "\n",
    "\n",
    "assert X_untransformed.shape[0] == y_untransformed.shape[0], 'X and y dimenssion must be the same.'\n",
    "print('Number of data: {}'.format(X_untransformed.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seccion\n",
      "Corporativo        82\n",
      "Cultura          3128\n",
      "Deportes        76458\n",
      "Economía         6750\n",
      "Entretención    29438\n",
      "Mundo           31664\n",
      "País            75180\n",
      "Sociedad         9079\n",
      "Tecnología       7130\n",
      "Name: Cuerpo, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes = df.groupby('Seccion')['Cuerpo'].nunique()\n",
    "\n",
    "print(classes)\n",
    "nClasses = classes.shape[0]\n",
    "\n",
    "#print('\\nNumber of classes: {}'.format(nClasses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraccion\n",
    "\n",
    "### Data representation\n",
    "\n",
    "TFID calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Normalize text\n",
      "Extract wordbags\n",
      "TFIDF end time :103.23783087730408\n",
      "Number of features: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "print(\"start\")\n",
    "\n",
    "\n",
    "spanish_stopwords = stopwords.words('spanish')\n",
    "def normalize_text(text):\n",
    "    return u\" \".join([x for x in [y for y in text.lower().strip().split(\" \")] \n",
    "                      if len(x) > 1 and x not in spanish_stopwords])\n",
    "\n",
    "X_untransformed = X_untransformed\n",
    "n_docs = X_untransformed.shape[0]\n",
    "n_cpu = 20\n",
    "\n",
    "batch_size = int(n_docs/n_cpu)\n",
    "\n",
    "wb = wordbatch.WordBatch(normalize_text, \n",
    "                         extractor=(WordBag, {\"hash_ngrams\": 1, \"hash_ngrams_weights\": [1.0, 1.0],\n",
    "                                              \"hash_size\": 2**28, \"norm\": \"l2\", \"tf\": 1.0,\n",
    "                                              \"idf\": 1.0}), procs=n_cpu, n_words=1000, minibatch_size=batch_size)\n",
    "wb.dictionary_freeze = True\n",
    "word_comment = wb.fit_transform(list(X_untransformed),reset= False)\n",
    "X_transformed = word_comment[:, np.array(np.clip(word_comment.getnnz(axis=0) - 1, 0, 1), dtype = bool)]\n",
    "\n",
    "end = time.time()\n",
    "print(\"TFIDF end time :\" + str(end - start) )\n",
    "\n",
    "X = X_transformed\n",
    "print('Number of features: {}'.format(X.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataObject():\n",
    "    def __init__(self, x, y,y2,y3):\n",
    "        self.X = x\n",
    "        self.Y = y\n",
    "        self.Y2 = y2\n",
    "        self.Y3 = y3\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            self.Y.reset_index(drop=True, inplace=True)\n",
    "            self.Y2.reset_index(drop=True, inplace=True)\n",
    "            self.Y3.reset_index(drop=True, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        self.X_train = self.X\n",
    "        self.Y_train = self.Y\n",
    "        self.X_test  = None\n",
    "        self.Y_test  = None\n",
    "        self.X_test_dense = None\n",
    "        self.k = 0\n",
    "        \n",
    "#     def next_train_batch(self, batch_size):\n",
    "#         indexes = np.random.choice(self.X_train.shape[0], size=batch_size, replace=False)\n",
    "#         return self.X_train[indexes], self.Y_train.reindex(indexes)\n",
    "\n",
    "    def set_train_test(self,train_fraction = None, test_fraction = None, dense=True):\n",
    "        # Tests for create subsets\n",
    "        if train_fraction == None and test_fraction == None:\n",
    "            train_fraction = 0.8\n",
    "        elif train_fraction == None:\n",
    "            assert 0 <= test_fraction and test_fraction < 1, 'Test fraction must be in [0,1)'\n",
    "            train_fraction = 1 - test_fraction\n",
    "        else:\n",
    "            assert 0 < train_fraction and train_fraction <= 1, 'Train fraction must be in (0,1]'\n",
    "\n",
    "        train_indices = np.random.choice(self.X.shape[0], round(train_fraction*self.X.shape[0]), replace=False)\n",
    "        test_indices = np.array(list(set(range(self.X.shape[0])) - set(train_indices)))\n",
    "\n",
    "        self.X_train = self.X[train_indices]\n",
    "        self.Y_train = self.Y.reindex(train_indices)\n",
    "        self.Y_train = self.Y_train.reset_index()\n",
    "        self.Y2_train = self.Y2.reindex(train_indices)\n",
    "        self.Y2_train = self.Y2_train.reset_index()\n",
    "        self.Y3_train = self.Y3.reindex(train_indices)\n",
    "        self.Y3_train = self.Y3_train.reset_index()        \n",
    "        \n",
    "        self.X_test = self.X[test_indices]\n",
    "        self.Y_test = self.Y.reindex(test_indices)\n",
    "        self.Y_test = self.Y_test.reset_index()\n",
    "        self.Y2_test = self.Y2.reindex(test_indices)\n",
    "        self.Y2_test = self.Y2_test.reset_index()\n",
    "        self.Y3_test = self.Y3.reindex(test_indices)\n",
    "        self.Y3_test = self.Y3_test.reset_index()        \n",
    "        if dense:\n",
    "            self.X_test_dense = self.X_test.todense()\n",
    "        return True\n",
    "\n",
    "def remove_accents(a):\n",
    "    #b = list(map(lambda x:unidecode.unidecode(x), a))\n",
    "    return unidecode.unidecode(a)\n",
    "    #return unidecode.unidecode(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = y_untransformed\n",
    "Y2 = y2_untransformed\n",
    "Y3= y3_untransformed\n",
    "\n",
    "Y = Y.reset_index(drop=True)\n",
    "Y2 = Y2.reset_index(drop=True)\n",
    "Y3 = Y3.reset_index(drop=True)\n",
    "\n",
    "Y = Y.apply(remove_accents)\n",
    "Y2 = Y2.apply(remove_accents)\n",
    "Y3 = Y3.apply(remove_accents)\n",
    "\n",
    "data = DataObject(X,Y,Y2,Y3)\n",
    "\n",
    "labels = [remove_accents(x) for x in list(data.Y.unique())]\n",
    "#print(labels)\n",
    "\n",
    "data.set_train_test(0.8)\n",
    "#print(data.Y_train.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Corporativo',\n",
       " 'Cultura',\n",
       " 'Deportes',\n",
       " 'Economia',\n",
       " 'Entretencion',\n",
       " 'Mundo',\n",
       " 'Pais',\n",
       " 'Sociedad',\n",
       " 'Tecnologia'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### DNN graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f51f5a6d8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': 500, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './tmp4'}\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column('x', dimension=1000)]\n",
    "#feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "classifier = DNNEstimator(                                \n",
    "                           head = tf.contrib.learn.multi_label_head(n_classes=9,weight_column_name='class_weights' ) , \n",
    "                           feature_columns=feature_columns,    \n",
    "                           hidden_units=[2000, 1000, 100],\n",
    "                           dropout=0.1,\n",
    "                           #model_dir = './model-parallel/seccion_dnn',\n",
    "                           model_dir = './tmp3',\n",
    "                           config = tf.contrib.learn.RunConfig(save_checkpoints_steps = 500,\n",
    "                           save_checkpoints_secs = None)\n",
    "                          )\n",
    "\n",
    "#tensorboard --logdir=./tmp2\n",
    "# 10.20.0.114:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9f29f70c50>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': 500, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './tmp5'}\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column('x', dimension=1000)]\n",
    "#feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "\n",
    "Y_ = data.Y_train\n",
    "Y_ = Y_['Seccion'].reset_index(drop=True)\n",
    "y = Y_.values\n",
    "label_keys_ = list(set(y))\n",
    "\n",
    "classifier = DNNEstimator(                                \n",
    "                           head = tf.contrib.learn.multi_class_head(n_classes=9,weight_column_name='class_weights',label_keys = label_keys_ ) , \n",
    "                           feature_columns=feature_columns,    \n",
    "                           hidden_units=[2000, 1000, 100],\n",
    "                           dropout=0.8,\n",
    "                           #model_dir = './model-parallel/seccion_dnn',\n",
    "                           model_dir = './tmp5',\n",
    "                           config = tf.contrib.learn.RunConfig(save_checkpoints_steps = 500,                           \n",
    "                           save_checkpoints_secs = None)\n",
    "                          )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions graph tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100000\n",
    "\n",
    "# Define the test inputs\n",
    "def get_train_inputs():\n",
    "    print(\"Paso por aca.........................\")\n",
    "    X_ = data.X_train\n",
    "    X_ = X_.todense()\n",
    "    x = X_\n",
    "\n",
    "    data.Y2_train[\"Seccion2\"] = data.Y2_train[\"Seccion2\"].replace(to_replace=\"Goles\", value='Deportes')\n",
    "    \n",
    "    Y_ = data.Y_train\n",
    "    Y2_ = data.Y2_train    \n",
    "    Y3_ = data.Y3_train\n",
    "    Y_ = Y_['Seccion'].reset_index(drop=True)\n",
    "    Y2_ = Y2_['Seccion2'].reset_index(drop=True)\n",
    "    Y3_ = Y3_['Seccion3'].reset_index(drop=True)\n",
    "    \n",
    "    y = Y_.values\n",
    "    y2 = Y2_.values\n",
    "    y3 = Y3_.values\n",
    "    #print(type(y))\n",
    "    \n",
    "    # computing lengths of each class\n",
    "    sizes = {label: Y_[Y_ == label].shape[0] for label in labels}\n",
    "\n",
    "    # creating weights for each sample\n",
    "    scale_factor = 10e3\n",
    "    weights = np.asarray([1.0/sizes[label] for label in y])\n",
    "    weights = scale_factor*weights\n",
    "    weights = weights[:,np.newaxis]\n",
    "    #print(weights)\n",
    "    \n",
    "    #print('weights shape: {}'.format(weights.shape))\n",
    "    \n",
    "    \n",
    "#     labels2 = list( set(y) )\n",
    "\n",
    "#     def to_multi_index(x1,x2,x3):\n",
    "#         tmp0 = [0]*len(labels2) \n",
    "#         tmp0[labels2.index(x1)] = 1\n",
    "#         tmp0[labels2.index(x2)] = 1\n",
    "#         tmp0[labels2.index(x3)] = 1        \n",
    "#         return tmp0    \n",
    "    \n",
    "#     y_tmp=[]\n",
    "#     for x1, x2, x3 in zip(y, y2, y3):\n",
    "#         y_tmp.append( to_multi_index(x1,x2,x3) )\n",
    "#     y = y_tmp\n",
    "\n",
    "#     print(np.sum(np.array(y),axis=1))\n",
    "    #print(y[:,np.newaxis])\n",
    "    \n",
    "#     dataset = tf.estimator.inputs.numpy_input_fn({'x': x, 'class_weights': weights}, np.array(y), shuffle=True, batch_size=500, num_epochs=epochs)\n",
    "    \n",
    "    dataset = tf.estimator.inputs.numpy_input_fn({'x': x, 'class_weights': weights}, y[:,np.newaxis], shuffle=True, batch_size=500, num_epochs=epochs)\n",
    "    return dataset\n",
    "\n",
    "def get_test_inputs():\n",
    "    X_ = data.X_test_dense\n",
    "    x = X_\n",
    "\n",
    "    \n",
    "    data.Y2_train[\"Seccion2\"] = data.Y2_train[\"Seccion2\"].replace(to_replace=\"Goles\", value='Deportes')\n",
    "    \n",
    "    Y_ = data.Y_test\n",
    "    Y2_ = data.Y2_test   \n",
    "    Y3_ = data.Y3_test\n",
    "    Y_ = Y_['Seccion'].reset_index(drop=True)\n",
    "    Y2_ = Y2_['Seccion2'].reset_index(drop=True)\n",
    "    Y3_ = Y3_['Seccion3'].reset_index(drop=True)\n",
    "    \n",
    "    y = Y_.values\n",
    "    y2 = Y2_.values\n",
    "    y3 = Y3_.values    \n",
    "    \n",
    "    # computing lengths of each class\n",
    "    sizes = {label: Y_[Y_ == label].shape[0] for label in labels}\n",
    "#     print(sizes)\n",
    "\n",
    "    # creating weights for each sample\n",
    "    scale_factor = 10e3\n",
    "    weights = np.asarray([1.0/sizes[label] for label in y])\n",
    "    weights = scale_factor*weights\n",
    "    weights = weights[:,np.newaxis]\n",
    "    print('weights shape: {}'.format(weights.shape))\n",
    "\n",
    "#     labels2 = list( set(y) )\n",
    "\n",
    "#     def to_multi_index(x1,x2,x3):\n",
    "#         tmp0 = [0]*len(labels2) \n",
    "#         tmp0[labels2.index(x1)] = 1\n",
    "#         tmp0[labels2.index(x2)] = 1\n",
    "#         tmp0[labels2.index(x3)] = 1        \n",
    "#         return tmp0    \n",
    "    \n",
    "#     y_tmp=[]\n",
    "#     for x1, x2, x3 in zip(y, y2, y3):\n",
    "#         y_tmp.append( to_multi_index(x1,x2,x3) )\n",
    "#     y = y_tmp\n",
    "\n",
    "#     dataset = tf.estimator.inputs.numpy_input_fn({'x': x, 'class_weights': weights}, np.array(y), shuffle=False)    \n",
    "    \n",
    "    dataset = tf.estimator.inputs.numpy_input_fn({'x': x, 'class_weights': weights}, y[:,np.newaxis], shuffle=False)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights shape: (47784, 1)\n",
      "Paso por aca.........................\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-11000\n",
      "INFO:tensorflow:Saving checkpoints for 11001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:39:42\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-11001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:39:46\n",
      "INFO:tensorflow:Saving dict for global step 11001: accuracy = 0.69313586, global_step = 11001, loss = 0.86225134\n",
      "INFO:tensorflow:Validation (step 11001): loss = 0.86225134, accuracy = 0.69313586, global_step = 11001\n",
      "INFO:tensorflow:loss = 1.117412, step = 11001\n",
      "INFO:tensorflow:global_step/sec: 10.8447\n",
      "INFO:tensorflow:loss = 0.609958, step = 11101 (4.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2254\n",
      "INFO:tensorflow:loss = 0.58190197, step = 11201 (4.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.969\n",
      "INFO:tensorflow:loss = 0.57942396, step = 11301 (4.354 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8134\n",
      "INFO:tensorflow:loss = 0.5393925, step = 11401 (4.383 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 11501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.7958\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:40:09\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-11501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:40:14\n",
      "INFO:tensorflow:Saving dict for global step 11501: accuracy = 0.7151736, global_step = 11501, loss = 0.91952986\n",
      "INFO:tensorflow:Validation (step 11501): loss = 0.91952986, accuracy = 0.7151736, global_step = 11501\n",
      "INFO:tensorflow:loss = 0.51933056, step = 11501 (9.897 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5033\n",
      "INFO:tensorflow:loss = 0.5646083, step = 11601 (4.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4949\n",
      "INFO:tensorflow:loss = 0.55611867, step = 11701 (4.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6861\n",
      "INFO:tensorflow:loss = 1.1113696, step = 11801 (4.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6443\n",
      "INFO:tensorflow:loss = 0.52949554, step = 11901 (4.416 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.2975\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:40:37\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-12001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:40:41\n",
      "INFO:tensorflow:Saving dict for global step 12001: accuracy = 0.7342329, global_step = 12001, loss = 0.88226414\n",
      "INFO:tensorflow:Validation (step 12001): loss = 0.88226414, accuracy = 0.7342329, global_step = 12001\n",
      "INFO:tensorflow:loss = 0.56301975, step = 12001 (9.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1509\n",
      "INFO:tensorflow:loss = 0.47486824, step = 12101 (4.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3001\n",
      "INFO:tensorflow:loss = 0.42512298, step = 12201 (4.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5412\n",
      "INFO:tensorflow:loss = 0.41999513, step = 12301 (4.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3627\n",
      "INFO:tensorflow:loss = 0.50259453, step = 12401 (4.472 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.9668\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:41:03\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-12501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:41:07\n",
      "INFO:tensorflow:Saving dict for global step 12501: accuracy = 0.7139837, global_step = 12501, loss = 0.834282\n",
      "INFO:tensorflow:Validation (step 12501): loss = 0.834282, accuracy = 0.7139837, global_step = 12501\n",
      "INFO:tensorflow:loss = 0.49776873, step = 12501 (9.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5576\n",
      "INFO:tensorflow:loss = 0.49194717, step = 12601 (4.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.9104\n",
      "INFO:tensorflow:loss = 0.43298188, step = 12701 (4.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2361\n",
      "INFO:tensorflow:loss = 0.4715568, step = 12801 (4.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4517\n",
      "INFO:tensorflow:loss = 0.4061239, step = 12901 (4.454 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.5966\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:41:30\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-13001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:41:34\n",
      "INFO:tensorflow:Saving dict for global step 13001: accuracy = 0.7426777, global_step = 13001, loss = 0.81148887\n",
      "INFO:tensorflow:Validation (step 13001): loss = 0.81148887, accuracy = 0.7426777, global_step = 13001\n",
      "INFO:tensorflow:loss = 0.42605335, step = 13001 (9.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1141\n",
      "INFO:tensorflow:loss = 0.47370794, step = 13101 (4.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6785\n",
      "INFO:tensorflow:loss = 0.49696016, step = 13201 (4.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5216\n",
      "INFO:tensorflow:loss = 0.4090646, step = 13301 (4.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.714\n",
      "INFO:tensorflow:loss = 0.44959673, step = 13401 (4.403 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.1233\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:41:57\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-13501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:42:01\n",
      "INFO:tensorflow:Saving dict for global step 13501: accuracy = 0.7316697, global_step = 13501, loss = 0.78936\n",
      "INFO:tensorflow:Validation (step 13501): loss = 0.78936, accuracy = 0.7316697, global_step = 13501\n",
      "INFO:tensorflow:loss = 0.40593976, step = 13501 (9.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9739\n",
      "INFO:tensorflow:loss = 0.422072, step = 13601 (4.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3414\n",
      "INFO:tensorflow:loss = 0.4388283, step = 13701 (4.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2307\n",
      "INFO:tensorflow:loss = 0.40508708, step = 13801 (4.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0368\n",
      "INFO:tensorflow:loss = 0.32952598, step = 13901 (4.539 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.2244\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:42:25\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-14001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:42:29\n",
      "INFO:tensorflow:Saving dict for global step 14001: accuracy = 0.7255049, global_step = 14001, loss = 0.7941722\n",
      "INFO:tensorflow:Validation (step 14001): loss = 0.7941722, accuracy = 0.7255049, global_step = 14001\n",
      "INFO:tensorflow:loss = 0.46229646, step = 14001 (9.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1875\n",
      "INFO:tensorflow:loss = 0.30038157, step = 14101 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3058\n",
      "INFO:tensorflow:loss = 0.38089034, step = 14201 (4.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.5715\n",
      "INFO:tensorflow:loss = 0.37810248, step = 14301 (4.635 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4283\n",
      "INFO:tensorflow:loss = 0.32192877, step = 14401 (4.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.8944\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:42:53\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-14501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:42:57\n",
      "INFO:tensorflow:Saving dict for global step 14501: accuracy = 0.7460747, global_step = 14501, loss = 0.77921796\n",
      "INFO:tensorflow:Validation (step 14501): loss = 0.77921796, accuracy = 0.7460747, global_step = 14501\n",
      "INFO:tensorflow:loss = 0.40814295, step = 14501 (9.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2886\n",
      "INFO:tensorflow:loss = 0.45529303, step = 14601 (4.536 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1669\n",
      "INFO:tensorflow:loss = 0.51493937, step = 14701 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0802\n",
      "INFO:tensorflow:loss = 0.46699512, step = 14801 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4896\n",
      "INFO:tensorflow:loss = 0.47288352, step = 14901 (4.446 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.1394\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:43:20\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-15001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:43:24\n",
      "INFO:tensorflow:Saving dict for global step 15001: accuracy = 0.7250065, global_step = 15001, loss = 0.7927703\n",
      "INFO:tensorflow:Validation (step 15001): loss = 0.7927703, accuracy = 0.7250065, global_step = 15001\n",
      "INFO:tensorflow:loss = 0.3789921, step = 15001 (9.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8884\n",
      "INFO:tensorflow:loss = 0.48190883, step = 15101 (4.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.164\n",
      "INFO:tensorflow:loss = 0.38344175, step = 15201 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9887\n",
      "INFO:tensorflow:loss = 0.44338223, step = 15301 (4.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2987\n",
      "INFO:tensorflow:loss = 0.42095616, step = 15401 (4.485 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 15501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.1182\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:43:47\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-15501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:43:51\n",
      "INFO:tensorflow:Saving dict for global step 15501: accuracy = 0.72707826, global_step = 15501, loss = 0.78579164\n",
      "INFO:tensorflow:Validation (step 15501): loss = 0.78579164, accuracy = 0.72707826, global_step = 15501\n",
      "INFO:tensorflow:loss = 0.42032623, step = 15501 (9.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.5023\n",
      "INFO:tensorflow:loss = 0.3738182, step = 15601 (4.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5119\n",
      "INFO:tensorflow:loss = 0.36028528, step = 15701 (4.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.0387\n",
      "INFO:tensorflow:loss = 0.43142325, step = 15801 (4.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8751\n",
      "INFO:tensorflow:loss = 0.3740552, step = 15901 (4.372 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.4687\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:44:14\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-16001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:44:18\n",
      "INFO:tensorflow:Saving dict for global step 16001: accuracy = 0.7466174, global_step = 16001, loss = 0.77003986\n",
      "INFO:tensorflow:Validation (step 16001): loss = 0.77003986, accuracy = 0.7466174, global_step = 16001\n",
      "INFO:tensorflow:loss = 0.3831156, step = 16001 (9.823 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4624\n",
      "INFO:tensorflow:loss = 0.34913024, step = 16101 (4.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8031\n",
      "INFO:tensorflow:loss = 0.37286565, step = 16201 (4.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5558\n",
      "INFO:tensorflow:loss = 0.37604704, step = 16301 (4.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2209\n",
      "INFO:tensorflow:loss = 0.38324785, step = 16401 (4.501 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 16501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.6817\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:44:42\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-16501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:44:46\n",
      "INFO:tensorflow:Saving dict for global step 16501: accuracy = 0.72969884, global_step = 16501, loss = 0.77868205\n",
      "INFO:tensorflow:Validation (step 16501): loss = 0.77868205, accuracy = 0.72969884, global_step = 16501\n",
      "INFO:tensorflow:loss = 0.34066278, step = 16501 (9.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9413\n",
      "INFO:tensorflow:loss = 0.40408307, step = 16601 (4.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6212\n",
      "INFO:tensorflow:loss = 0.3097336, step = 16701 (4.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6463\n",
      "INFO:tensorflow:loss = 0.3507744, step = 16801 (4.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4249\n",
      "INFO:tensorflow:loss = 0.29728654, step = 16901 (4.459 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.34\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:45:08\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-17001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:45:12\n",
      "INFO:tensorflow:Saving dict for global step 17001: accuracy = 0.72680396, global_step = 17001, loss = 0.78555477\n",
      "INFO:tensorflow:Validation (step 17001): loss = 0.78555477, accuracy = 0.72680396, global_step = 17001\n",
      "INFO:tensorflow:loss = 0.28680208, step = 17001 (8.878 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.561\n",
      "INFO:tensorflow:loss = 0.33239293, step = 17101 (4.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.75\n",
      "INFO:tensorflow:loss = 0.3517408, step = 17201 (4.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2766\n",
      "INFO:tensorflow:loss = 0.3373676, step = 17301 (4.298 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4657\n",
      "INFO:tensorflow:loss = 0.36671627, step = 17401 (4.452 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 17501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.2707\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:45:36\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-17501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:45:40\n",
      "INFO:tensorflow:Saving dict for global step 17501: accuracy = 0.73178625, global_step = 17501, loss = 0.7730182\n",
      "INFO:tensorflow:Validation (step 17501): loss = 0.7730182, accuracy = 0.73178625, global_step = 17501\n",
      "INFO:tensorflow:loss = 0.39579725, step = 17501 (9.917 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2681\n",
      "INFO:tensorflow:loss = 0.41134322, step = 17601 (4.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4374\n",
      "INFO:tensorflow:loss = 0.26743844, step = 17701 (4.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7525\n",
      "INFO:tensorflow:loss = 0.35045567, step = 17801 (4.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3356\n",
      "INFO:tensorflow:loss = 0.3729121, step = 17901 (4.479 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.0317\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:46:03\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-18001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:46:07\n",
      "INFO:tensorflow:Saving dict for global step 18001: accuracy = 0.72594446, global_step = 18001, loss = 0.79114205\n",
      "INFO:tensorflow:Validation (step 18001): loss = 0.79114205, accuracy = 0.72594446, global_step = 18001\n",
      "INFO:tensorflow:loss = 0.30496755, step = 18001 (9.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8656\n",
      "INFO:tensorflow:loss = 0.32502288, step = 18101 (4.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0871\n",
      "INFO:tensorflow:loss = 0.37738597, step = 18201 (4.528 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2729\n",
      "INFO:tensorflow:loss = 0.36877513, step = 18301 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2867\n",
      "INFO:tensorflow:loss = 0.38084847, step = 18401 (4.486 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 18501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.7837\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:46:31\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-18501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:46:35\n",
      "INFO:tensorflow:Saving dict for global step 18501: accuracy = 0.7307939, global_step = 18501, loss = 0.7746544\n",
      "INFO:tensorflow:Validation (step 18501): loss = 0.7746544, accuracy = 0.7307939, global_step = 18501\n",
      "INFO:tensorflow:loss = 0.3264604, step = 18501 (9.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4904\n",
      "INFO:tensorflow:loss = 0.2956845, step = 18601 (4.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6475\n",
      "INFO:tensorflow:loss = 0.42826122, step = 18701 (4.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5788\n",
      "INFO:tensorflow:loss = 0.30680636, step = 18801 (4.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9545\n",
      "INFO:tensorflow:loss = 0.40109736, step = 18901 (4.555 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.6942\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:46:58\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-19001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:47:02\n",
      "INFO:tensorflow:Saving dict for global step 19001: accuracy = 0.72878724, global_step = 19001, loss = 0.7845996\n",
      "INFO:tensorflow:Validation (step 19001): loss = 0.7845996, accuracy = 0.72878724, global_step = 19001\n",
      "INFO:tensorflow:loss = 0.3494983, step = 19001 (9.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9621\n",
      "INFO:tensorflow:loss = 0.39852303, step = 19101 (4.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4006\n",
      "INFO:tensorflow:loss = 0.39274034, step = 19201 (4.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5003\n",
      "INFO:tensorflow:loss = 0.32632032, step = 19301 (4.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.292\n",
      "INFO:tensorflow:loss = 0.4164177, step = 19401 (4.487 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 19501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.0329\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:47:25\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-19501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:47:29\n",
      "INFO:tensorflow:Saving dict for global step 19501: accuracy = 0.72761035, global_step = 19501, loss = 0.8005973\n",
      "INFO:tensorflow:Validation (step 19501): loss = 0.8005973, accuracy = 0.72761035, global_step = 19501\n",
      "INFO:tensorflow:loss = 0.400004, step = 19501 (8.801 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.7872\n",
      "INFO:tensorflow:loss = 0.34662494, step = 19601 (4.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.338\n",
      "INFO:tensorflow:loss = 0.3199394, step = 19701 (4.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3221\n",
      "INFO:tensorflow:loss = 0.4141921, step = 19801 (4.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1276\n",
      "INFO:tensorflow:loss = 0.38062465, step = 19901 (4.519 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.7295\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:47:52\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-20001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:47:56\n",
      "INFO:tensorflow:Saving dict for global step 20001: accuracy = 0.72809005, global_step = 20001, loss = 0.7993983\n",
      "INFO:tensorflow:Validation (step 20001): loss = 0.7993983, accuracy = 0.72809005, global_step = 20001\n",
      "INFO:tensorflow:loss = 0.35292667, step = 20001 (9.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.752\n",
      "INFO:tensorflow:loss = 0.3468815, step = 20101 (4.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2394\n",
      "INFO:tensorflow:loss = 0.33257547, step = 20201 (4.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0612\n",
      "INFO:tensorflow:loss = 0.2678607, step = 20301 (4.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2641\n",
      "INFO:tensorflow:loss = 0.29972282, step = 20401 (4.492 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.1587\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:48:20\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-20501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:48:24\n",
      "INFO:tensorflow:Saving dict for global step 20501: accuracy = 0.7219458, global_step = 20501, loss = 0.8045973\n",
      "INFO:tensorflow:Validation (step 20501): loss = 0.8045973, accuracy = 0.7219458, global_step = 20501\n",
      "INFO:tensorflow:loss = 0.33189085, step = 20501 (9.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8582\n",
      "INFO:tensorflow:loss = 0.34732038, step = 20601 (4.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.166\n",
      "INFO:tensorflow:loss = 0.3006214, step = 20701 (4.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.6362\n",
      "INFO:tensorflow:loss = 0.35111392, step = 20801 (4.623 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.365\n",
      "INFO:tensorflow:loss = 0.26082042, step = 20901 (4.470 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.1257\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:48:47\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-21001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:48:51\n",
      "INFO:tensorflow:Saving dict for global step 21001: accuracy = 0.72859305, global_step = 21001, loss = 0.799996\n",
      "INFO:tensorflow:Validation (step 21001): loss = 0.799996, accuracy = 0.72859305, global_step = 21001\n",
      "INFO:tensorflow:loss = 0.32551545, step = 21001 (8.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.3936\n",
      "INFO:tensorflow:loss = 0.53454673, step = 21101 (4.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.196\n",
      "INFO:tensorflow:loss = 0.29750946, step = 21201 (4.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1501\n",
      "INFO:tensorflow:loss = 0.31371838, step = 21301 (4.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4413\n",
      "INFO:tensorflow:loss = 0.2759091, step = 21401 (4.455 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 21501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.8921\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:49:14\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-21501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:49:18\n",
      "INFO:tensorflow:Saving dict for global step 21501: accuracy = 0.72892123, global_step = 21501, loss = 0.79162735\n",
      "INFO:tensorflow:Validation (step 21501): loss = 0.79162735, accuracy = 0.72892123, global_step = 21501\n",
      "INFO:tensorflow:loss = 0.34223762, step = 21501 (9.269 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1474\n",
      "INFO:tensorflow:loss = 0.3524439, step = 21601 (4.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.8139\n",
      "INFO:tensorflow:loss = 0.2797868, step = 21701 (4.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6141\n",
      "INFO:tensorflow:loss = 0.4255161, step = 21801 (4.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.459\n",
      "INFO:tensorflow:loss = 0.3063606, step = 21901 (4.453 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 21.3984\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:49:41\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-22001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:49:45\n",
      "INFO:tensorflow:Saving dict for global step 22001: accuracy = 0.7183499, global_step = 22001, loss = 0.813439\n",
      "INFO:tensorflow:Validation (step 22001): loss = 0.813439, accuracy = 0.7183499, global_step = 22001\n",
      "INFO:tensorflow:loss = 0.25203297, step = 22001 (9.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7473\n",
      "INFO:tensorflow:loss = 0.3137318, step = 22101 (4.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.0709\n",
      "INFO:tensorflow:loss = 0.305159, step = 22201 (4.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.2864\n",
      "INFO:tensorflow:loss = 0.31121397, step = 22301 (4.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.1595\n",
      "INFO:tensorflow:loss = 0.31486705, step = 22401 (4.512 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 22501 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.6778\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:50:09\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-22501\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:50:13\n",
      "INFO:tensorflow:Saving dict for global step 22501: accuracy = 0.723629, global_step = 22501, loss = 0.82367694\n",
      "INFO:tensorflow:Validation (step 22501): loss = 0.82367694, accuracy = 0.723629, global_step = 22501\n",
      "INFO:tensorflow:loss = 0.28873545, step = 22501 (9.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3887\n",
      "INFO:tensorflow:loss = 0.28093073, step = 22601 (4.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.024\n",
      "INFO:tensorflow:loss = 0.30706763, step = 22701 (4.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3322\n",
      "INFO:tensorflow:loss = 0.23440158, step = 22801 (4.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.3392\n",
      "INFO:tensorflow:loss = 0.2714464, step = 22901 (4.476 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 23001 into ./tmp5/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 20.9843\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-16-13:50:37\n",
      "INFO:tensorflow:Restoring parameters from ./tmp5/model.ckpt-23001\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-16-13:50:41\n",
      "INFO:tensorflow:Saving dict for global step 23001: accuracy = 0.7304191, global_step = 23001, loss = 0.81085706\n",
      "INFO:tensorflow:Validation (step 23001): loss = 0.81085706, accuracy = 0.7304191, global_step = 23001\n",
      "INFO:tensorflow:Stopping. Best step: 16001 with loss = 0.7700398564338684.\n",
      "INFO:tensorflow:loss = 0.26098225, step = 23001 (9.315 sec)\n",
      "INFO:tensorflow:Loss for final step: 0.26098225.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNEstimator(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._MultiClassHead object at 0x7f9f29f70b00>, 'hidden_units': [2000, 1000, 100], 'feature_columns': [_RealValuedColumn(column_name='x', dimension=1000, default_value=None, dtype=tf.float32, normalizer=None)], 'optimizer': None, 'activation_fn': <function relu at 0x7fa0236db2f0>, 'dropout': 0.8, 'gradient_clip_norm': None, 'embedding_lr_multipliers': None, 'input_layer_min_slice_size': None})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    input_fn= get_test_inputs(),\n",
    "    every_n_steps=500,\n",
    "    #early_stopping_metric=\"accuracy\",\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=7000\n",
    "    )\n",
    "\n",
    "#classifier.fit(input_fn=get_train_inputs(), monitors=[validation_monitor], steps=epochs, max_steps=None)\n",
    "classifier.fit(input_fn=get_train_inputs(), monitors=[validation_monitor], max_steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = classifier.evaluate(input_fn=get_test_inputs,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inputs():\n",
    "    X_ = data.X_test_dense\n",
    "    x = X_\n",
    "    \n",
    "\n",
    "    \n",
    "    data.Y2_train[\"Seccion2\"] = data.Y2_train[\"Seccion2\"].replace(to_replace=\"Goles\", value='Deportes')\n",
    "    \n",
    "    Y_ = data.Y_test\n",
    "    Y2_ = data.Y2_test   \n",
    "    Y3_ = data.Y3_test\n",
    "    Y_ = Y_['Seccion'].reset_index(drop=True)\n",
    "    Y2_ = Y2_['Seccion2'].reset_index(drop=True)\n",
    "    Y3_ = Y3_['Seccion3'].reset_index(drop=True)\n",
    "    \n",
    "    y = Y_.values\n",
    "    y2 = Y2_.values\n",
    "    y3 = Y3_.values    \n",
    "    \n",
    "    # computing lengths of each class\n",
    "    sizes = {label: Y_[Y_ == label].shape[0] for label in labels}\n",
    "#     print(sizes)\n",
    "\n",
    "    # creating weights for each sample\n",
    "    scale_factor = 10e3\n",
    "    weights = np.asarray([1.0/sizes[label] for label in y])\n",
    "    weights = scale_factor*weights\n",
    "    weights = weights[:,np.newaxis]\n",
    "    print('weights shape: {}'.format(weights.shape))\n",
    "\n",
    "    labels2 = list( set(y) )\n",
    "\n",
    "    def to_multi_index(x1,x2,x3):\n",
    "        tmp0 = [0]*len(labels2) \n",
    "        tmp0[labels2.index(x1)] = 1\n",
    "        tmp0[labels2.index(x2)] = 1\n",
    "        tmp0[labels2.index(x3)] = 1        \n",
    "        return tmp0    \n",
    "    \n",
    "    y_tmp=[]\n",
    "    for x1, x2, x3 in zip(y, y2, y3):\n",
    "        y_tmp.append( to_multi_index(x1,x2,x3) )\n",
    "    y = y_tmp    \n",
    "    \n",
    "    x = tf.constant(x)\n",
    "    class_weights =tf.constant(weights) \n",
    "    y = tf.constant(np.array(y))    \n",
    "    return {'x':x,'class_weights': class_weights}, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = classifier.evaluate(input_fn=test_inputs,steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = list(classifier.predict(input_fn = test_inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "print('Accuracy in test: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions[1:10]\n",
    "\n",
    "out = list(map(lambda x:x[\"classes\"] ,predictions))\n",
    "sums = np.sum(out,axis = 1)\n",
    "total = sum(sums==3)\n",
    "print(total)\n",
    "print(len(sums))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "import sklearn\n",
    "sklearn.metrics.confusion_matrix(out, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_evaluate():\n",
    "    dataset = {'x': tf.constant(data.X_test_dense)}\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "pred_test = classifier.predict(input_fn=input_fn=get_test_inputs)\n",
    "\n",
    "# print(pred_test)\n",
    "\n",
    "y_test_hat = np.asarray([x.decode('UTF-8') for x in list(pred_test)])\n",
    "y_test_hat = y_test_hat.astype(str)\n",
    "y_test = data.Y_test['Seccion'].values\n",
    "y_test = y_test.astype(str)\n",
    "print('Test shape: {}\\nReal shape: {}'.format(y_test_hat.shape, y_test.shape))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_test_hat)\n",
    "print('Accuracy in test: {}'.format(acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pred_test = list(classifier.predict(input_fn = get_test_inputs))\n",
    "print(predictions[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = list(map(lambda x:x[\"classes\"] ,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = list(map(lambda x:x[\"classes\"] ,predictions))\n",
    "out = np.array(out)\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def confusion_matrix(yt, yp, classes):\n",
    "    instcount = yt.shape[0]\n",
    "    n_classes = classes.shape[0]\n",
    "    mtx = np.zeros((n_classes, 4))\n",
    "    for i in range(instcount):\n",
    "        for c in range(n_classes):\n",
    "            mtx[c,0] += 1 if yt[i,c]==1 and yp[i,c]==1 else 0\n",
    "            mtx[c,1] += 1 if yt[i,c]==1 and yp[i,c]==0 else 0\n",
    "            mtx[c,2] += 1 if yt[i,c]==0 and yp[i,c]==0 else 0\n",
    "            mtx[c,3] += 1 if yt[i,c]==0 and yp[i,c]==1 else 0\n",
    "    mtx = [[m0/(m0+m1), m1/(m0+m1), m2/(m2+m3), m3/(m2+m3)] for m0,m1,m2,m3 in mtx]\n",
    "    plt.figure(num=None, figsize=(5, 15), dpi=100, facecolor='w', edgecolor='k')\n",
    "    plt.imshow(mtx, interpolation='nearest',cmap='Blues')\n",
    "    plt.title(\"title\")\n",
    "    tick_marks = np.arange(n_classes)\n",
    "    plt.xticks(np.arange(4), ['1 - 1','1 - 0','0 - 0','0 - 1'])\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    for i, j in itertools.product(range(n_classes), range(4)):\n",
    "        plt.text(j, i, round(mtx[i][j],2), horizontalalignment=\"center\")\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel('labels')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix(out, out,[1 1 1 1 1 1 1 1 1])\n",
    "    \n",
    "# y1 = np.genfromtxt('y_true.csv', delimiter=\",\")\n",
    "# y2 = np.genfromtxt('y_pred.csv', delimiter=\",\")\n",
    "# labels = np.genfromtxt('labels.csv', delimiter=\",\", dtype=\"|S\")\n",
    "# confusion_matrix(y1, y2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = data.Y_test['Seccion'].values\n",
    "y_test = y_test.astype(str)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =get_train_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with sess.as_default()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = classifier.predict_proba(input_fn=input_fn_evaluate,as_iterable=False)\n",
    "np.sum(predict_proba, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = skplt.plot_confusion_matrix(y_test, y_test_hat,normalize=True)\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "for tick in ax.xaxis.get_minor_ticks():\n",
    "    tick.tick1line.set_markersize(0)\n",
    "    tick.tick2line.set_markersize(0)\n",
    "    tick.label1.set_horizontalalignment('center')\n",
    "\n",
    "plt2.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
