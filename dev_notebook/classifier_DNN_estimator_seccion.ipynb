{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Utils\n",
    "import os, sys, re, time, gc, types, string, unicodedata, unidecode, string, warnings, inspect\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import shutil\n",
    "\n",
    "from tensorflow.contrib.learn import DNNClassifier\n",
    "import scikitplot as skplt\n",
    "\n",
    "#plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../\"\n",
    "path_model = root_path + 'models/test'\n",
    "#features_path = root_path + 'data/features/data_tfid_hash28_n1000_SVD2.p'\n",
    "features_path = root_path + 'data/features/data_tfid_hash28_n10000.p'\n",
    "\n",
    "delete_old_model = True\n",
    "if delete_old_model:\n",
    "    try:\n",
    "        os.system(\"rm -rf \"+path_model)\n",
    "        os.system(\"mkdir \"+path_model)\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X ,y1 ,y2 , y3 = pickle.load( open( features_path, \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fraction = 0.8\n",
    "\n",
    "y1 = y1.values    \n",
    "\n",
    "np.random.seed(42)\n",
    "train_indices = np.random.choice(X.shape[0], round(train_fraction*X.shape[0]), replace=False)\n",
    "test_indices = np.array(list(set(range(X.shape[0])) - set(train_indices)))\n",
    "\n",
    "X_train = X[train_indices]\n",
    "y_train = y1[train_indices]\n",
    "X_test = X[test_indices]\n",
    "y_test = y1[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(y_train))\n",
    "labels.sort()\n",
    "nClasses = len(labels)\n",
    "\n",
    "def calcWeights(y):\n",
    "    sizes = {label: y_train[y_train == label].shape[0] for label in labels}\n",
    "    weights = np.asarray([float(len(y_train))/(sizes[label]*nClasses) for label in y]) #n_samples / (n_classes * np.bincount(y))\n",
    "    weights = np.power(weights,1) # 1.4\n",
    "    return weights \n",
    "\n",
    "def calcWeightsL(y):\n",
    "    #lerko\n",
    "    scale_factor = 10e3\n",
    "    sizes = {label: y_train[y_train == label].shape[0] for label in labels}\n",
    "    weights = np.asarray([scale_factor/sizes[label] for label in y])\n",
    "    return weights \n",
    "\n",
    "weights_train = calcWeights(y_train)\n",
    "weights_test = calcWeights(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### DNN graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 9000\n",
    "X_train = X_train.todense()\n",
    "X_test = X_test.todense()\n",
    "\n",
    "# Define the test inputs\n",
    "def get_train_inputs():    \n",
    "    dataset = tf.estimator.inputs.numpy_input_fn({'x': X_train,'class_weights': weights_train},\n",
    "                                                  y_train[:,np.newaxis],\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=50,\n",
    "                                                  num_epochs=epochs)\n",
    "    return dataset\n",
    "\n",
    "def get_test_inputs():\n",
    "    dataset = tf.estimator.inputs.numpy_input_fn({'x': X_test,'class_weights': weights_test},\n",
    "                                                  y_test[:,np.newaxis],\n",
    "                                                  shuffle=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions graph tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-dff18f6805e1>:19: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:378: multi_class_head (from tensorflow.contrib.learn.python.learn.estimators.head) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.contrib.estimator.*_head.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py:1180: BaseEstimator.__init__ (from tensorflow.contrib.learn.python.learn.estimators.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please replace uses of any Estimator from tf.contrib.learn with an Estimator from tf.estimator.*\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7c6ad26048>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': 500, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '../models/test'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "feature_columns = [tf.contrib.layers.real_valued_column('x', dimension=X_train.shape[1])]\n",
    "\n",
    "optimizer = tf.train.ProximalAdagradOptimizer(\n",
    "                              learning_rate=0.1,\n",
    "                              l1_regularization_strength= 0.0#0.0001\n",
    "                              )\n",
    "\n",
    "classifier = DNNClassifier(                                \n",
    "                           n_classes=len(labels), label_keys=labels, feature_columns=feature_columns,\n",
    "                           hidden_units=[20000], #2000, 1000, 100\n",
    "                           dropout=0.5,\n",
    "                           #optimizer = optimizer,\n",
    "                           weight_column_name='class_weights',\n",
    "                           model_dir = path_model,\n",
    "                           config = tf.contrib.learn.RunConfig(save_checkpoints_steps = 500,\n",
    "                           save_checkpoints_secs = None)                           \n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/monitors.py:279: BaseMonitor.__init__ (from tensorflow.contrib.learn.python.learn.monitors) is deprecated and will be removed after 2016-12-05.\n",
      "Instructions for updating:\n",
      "Monitors are deprecated. Please use tf.train.SessionRunHook.\n",
      "start\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Weights class_weights has shape (?,), expanding to make it 2d.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:678: ModelFnOps.__new__ (from tensorflow.contrib.learn.python.learn.estimators.model_fn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.EstimatorSpec. You can use the `estimator_spec` method to create an equivalent one.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ../models/test/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2034545, step = 1\n",
      "INFO:tensorflow:global_step/sec: 2.22361\n",
      "INFO:tensorflow:loss = 2.0438492, step = 101 (44.974 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.36451\n",
      "INFO:tensorflow:loss = 1.6553043, step = 201 (42.292 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.35149\n",
      "INFO:tensorflow:loss = 2.1151736, step = 301 (42.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.33702\n",
      "INFO:tensorflow:loss = 1.182774, step = 401 (42.789 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into ../models/test/model.ckpt.\n",
      "WARNING:tensorflow:Weights class_weights has shape (?,), expanding to make it 2d.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-05-20:42:45\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/test/model.ckpt-500\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-05-20:43:39\n",
      "INFO:tensorflow:Saving dict for global step 500: accuracy = 0.7158442, global_step = 500, loss = 1.386702\n",
      "INFO:tensorflow:Validation (step 500): loss = 1.386702, accuracy = 0.7158442, global_step = 500\n",
      "INFO:tensorflow:global_step/sec: 1.00483\n",
      "INFO:tensorflow:loss = 1.1641552, step = 501 (99.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.37774\n",
      "INFO:tensorflow:loss = 1.2544649, step = 601 (42.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.3449\n",
      "INFO:tensorflow:loss = 0.85294515, step = 701 (42.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.32299\n",
      "INFO:tensorflow:loss = 0.86052424, step = 801 (43.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20392\n",
      "INFO:tensorflow:loss = 1.2132396, step = 901 (45.372 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ../models/test/model.ckpt.\n",
      "WARNING:tensorflow:Weights class_weights has shape (?,), expanding to make it 2d.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-05-20:47:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ../models/test/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-05-20:48:14\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.79213685, global_step = 1000, loss = 0.7833816\n",
      "INFO:tensorflow:Validation (step 1000): loss = 0.7833816, accuracy = 0.79213685, global_step = 1000\n",
      "INFO:tensorflow:global_step/sec: 0.987383\n",
      "INFO:tensorflow:loss = 0.6660713, step = 1001 (101.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.20956\n",
      "INFO:tensorflow:loss = 0.72046965, step = 1101 (45.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 2.19712\n",
      "INFO:tensorflow:loss = 1.1580896, step = 1201 (45.514 sec)\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "\n",
    "    \n",
    "validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    #input_fn= get_train_inputs(),\n",
    "    input_fn= get_test_inputs(),\n",
    "    \n",
    "    every_n_steps=500,\n",
    "    #early_stopping_metric=\"accuracy\",#loss\n",
    "    early_stopping_metric=\"loss\",\n",
    "    early_stopping_metric_minimize=True,\n",
    "    early_stopping_rounds=3000)\n",
    "\n",
    "start = time.time()\n",
    "print(\"start\")\n",
    "\n",
    "#classifier.fit(input_fn=get_train_inputs(), monitors=[validation_monitor], steps=epochs, max_steps=None)\n",
    "classifier.fit(input_fn=get_train_inputs(), monitors=[validation_monitor], steps=epochs, max_steps=None)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Training time :\" + str(end - start) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test = X_test.todense()\n",
    "\n",
    "def input_fn_evaluate():\n",
    "    dataset = {'x': tf.constant(X_test)}    \n",
    "    return dataset\n",
    "\n",
    "pred_test = classifier.predict_classes(input_fn=input_fn_evaluate)\n",
    "y_test_hat = np.asarray([x.decode('UTF-8') for x in list(pred_test)])\n",
    "y_test_hat = y_test_hat.astype(str)\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_test_hat)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_test, y_test_hat,normalize='True')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "#print('Accuracy in test: {}'.format(acc))\n",
    "display(Markdown('## Accuracy in test: {} '.format(acc*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
