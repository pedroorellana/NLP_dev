{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import re, sys, unidecode\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import scikitplot as skplt\n",
    "\n",
    "from tensorflow.contrib.learn import DNNClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../\"\n",
    "path_model = root_path + 'models/seccion'\n",
    "features_path = root_path + 'data/features/data_tfid_hash28_n1000_SVD2.p'\n",
    "\n",
    "delete_old_model = True\n",
    "if delete_old_model:\n",
    "    try:\n",
    "        os.system(\"rm -rf \"+path_model)\n",
    "        os.system(\"mkdir \"+path_model)\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y1, y2, y3 = pickle.load( open( features_path, \"rb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre procesing\n",
    "\n",
    "Cleaning data, select clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = np.array(y2)\n",
    "y_2 = list(map(lambda x: unidecode.unidecode(x) if x!=None else None, y2))\n",
    "y_2 = np.array(y_2)\n",
    "\n",
    "\n",
    "y1 = y1.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraccion\n",
    "\n",
    "### Data representation\n",
    "\n",
    "TFID calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(set(y1))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterClases(X,y,umbral):\n",
    "    labels = list(set(y))\n",
    "    sizes = [ [label,y[y== label].shape[0]] for label in labels ]\n",
    "    filter_sizes = list(filter(lambda x:x[1]>umbral ,sizes ))\n",
    "    names_clases = set( map(lambda x:x[0], filter_sizes ) )\n",
    "    index = list(map(lambda x: {x}.issubset(names_clases), y ))\n",
    "    y = y[index]\n",
    "    X = X[np.nonzero(index)]\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_temas = {}\n",
    "X_temas = {}\n",
    "labels_temas = {}\n",
    "labels_temas_before = {}\n",
    "umbral_ejemplos = 100\n",
    "\n",
    "for key in labels:\n",
    "    index = y1 == key\n",
    "    y_22 = y_2[index]\n",
    "    X2 = X[np.nonzero(index)]\n",
    "\n",
    "    index = y_22 != None\n",
    "    y_22 = y_22[index]\n",
    "    X2 = X2[np.nonzero(index)]\n",
    "    X_temas[key],y_temas[key] = filterClases(X2,y_22,umbral_ejemplos)\n",
    "    \n",
    "    \n",
    "    labels_temas_before = list(set(y_22))\n",
    "    labels_temas[key] = list(set(y_temas[key]))\n",
    "    \n",
    "    print(\"\\n\"+key + \" ,total : \" + str(len(labels_temas[key])) \\\n",
    "          +\" ,deleted : \"+ str( len(labels_temas_before) - len(labels_temas[key] )) )\n",
    "    print(labels_temas[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "train_fraction = 0.8\n",
    "\n",
    "X_train = {}\n",
    "y_train = {}\n",
    "X_test = {}\n",
    "y_test = {}\n",
    "train_indices = {}\n",
    "test_indices = {}\n",
    "\n",
    "for key in labels:\n",
    "    train_indices[key] = np.random.choice(X_temas[key].shape[0], round(train_fraction*X_temas[key].shape[0]), replace=False)\n",
    "    test_indices[key] = np.array(list(set(range(X_temas[key].shape[0])) - set(train_indices)))\n",
    "\n",
    "    X_train[key] = X_temas[key][train_indices[key]]\n",
    "    y_train[key] = y_temas[key][train_indices[key]]\n",
    "    X_test[key] = X_temas[key][test_indices[key]]\n",
    "    y_test[key] = y_temas[key][test_indices[key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_train = {}\n",
    "weights_test = {}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "for key in labels:\n",
    "    labelsTmp = list(set(y_train[key]))\n",
    "    nClasses = len(labelsTmp)\n",
    "\n",
    "    sizes = {label: y_train[key][y_train[key] == label].shape[0] for label in labelsTmp}\n",
    "    weights = np.asarray([len(y_train[key])/(sizes[label]*nClasses) for label in y_temas[key]])\n",
    "\n",
    "    weights = weights[:,np.newaxis]\n",
    "    weights_train[key] = weights[train_indices[key]]\n",
    "    weights_test[key] = weights[test_indices[key]]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "### DNN graph generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 14000\n",
    "\n",
    "# Define the test inputs\n",
    "def get_train_inputs(key):    \n",
    "    dataset = tf.estimator.inputs.numpy_input_fn({'x': X_train[key].todense(),'class_weights': weights_train[key]},\n",
    "                                                  y_train[key][:,np.newaxis],\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=50,\n",
    "                                                  num_epochs=epochs)\n",
    "    return dataset\n",
    "\n",
    "def get_test_inputs(key):   \n",
    "    dataset = tf.estimator.inputs.numpy_input_fn({'x': X_test[key].todense(),'class_weights': weights_test[key]},\n",
    "                                                  y_test[key][:,np.newaxis],\n",
    "                                                  shuffle=False)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions graph tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tf.set_random_seed(42)\n",
    "feature_columns = [tf.contrib.layers.real_valued_column('x', dimension=1000)]\n",
    "\n",
    "classifier = {}\n",
    "path_all_models  = {}\n",
    "for key in labels:\n",
    "    path_all_models[key] = path_model+\"/\"+str(key)\n",
    "    classifier[key] = DNNClassifier(                                \n",
    "                               n_classes=len(labels_temas[key]), label_keys=labels_temas[key], feature_columns=feature_columns,\n",
    "                               hidden_units=[2000],\n",
    "                               dropout=0.5,\n",
    "                               weight_column_name='class_weights',\n",
    "                               model_dir = path_model+\"/\"+str(key),\n",
    "                               config = tf.contrib.learn.RunConfig(save_checkpoints_steps = 500,\n",
    "                               save_checkpoints_secs = None)                           \n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_monitor = {}\n",
    "\n",
    "print(\"start\")\n",
    "start = time.time()\n",
    "\n",
    "for key in labels:\n",
    "    \n",
    "    validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "        #input_fn= get_train_inputs(),\n",
    "        input_fn= get_test_inputs(key),    \n",
    "        every_n_steps=500,\n",
    "        #early_stopping_metric=\"accuracy\",#loss\n",
    "        early_stopping_metric=\"loss\",\n",
    "        early_stopping_metric_minimize=True,\n",
    "        early_stopping_rounds=2000)\n",
    "\n",
    "    \n",
    "\n",
    "    classifier[key].fit(input_fn=get_train_inputs(key), monitors=[validation_monitor], steps=epochs, max_steps=None)\n",
    "    print(\"###################### \"+key+\" ######################\")\n",
    "    \n",
    "end = time.time()\n",
    "#print(key)\n",
    "print(\"Training time :\" + str(end - start) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = {}\n",
    "y_test_hat = {}\n",
    "y_test_hat = {}\n",
    "acc = {}\n",
    "\n",
    "for key in labels:\n",
    "\n",
    "    def input_fn_evaluate():\n",
    "        dataset = {'x': tf.constant(X_test[key].todense())}    \n",
    "        return dataset\n",
    "\n",
    "    pred_test[key] = classifier[key].predict_classes(input_fn=input_fn_evaluate)\n",
    "    y_test_hat[key] = np.asarray([x.decode('UTF-8') for x in list(pred_test[key])])\n",
    "    y_test_hat[key] = y_test_hat[key].astype(str)\n",
    "    acc[key] = accuracy_score(y_true=y_test[key], y_pred=y_test_hat[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in labels:\n",
    "    display(Markdown('## ' + key))\n",
    "    display(Markdown('## Accuracy in test: {} '.format(acc[key]*100)))    \n",
    "    skplt.metrics.plot_confusion_matrix(y_test[key], y_test_hat[key],normalize=True,figsize=(20,20))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    #print('Accuracy in test: {}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save info model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( (path_all_models,labels_temas), open( path_model + \"/info_model.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
