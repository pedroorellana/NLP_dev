{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "import os, sys, re, time, gc, types, string, unicodedata, unidecode, string, warnings, inspect\n",
    "\n",
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import re, sys, unidecode\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Representation\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "import wordbatch\n",
    "from wordbatch.extractors import WordBag, WordHash\n",
    "from wordbatch.models import FTRL\n",
    "\n",
    "#plt.style.use('fivethirtyeight')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#Carga stop word\n",
    "#nltk.download('stopwords')\n",
    "spanish_stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "# punkt:  módulo contiene modelos para la tokenización de textos\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../\"\n",
    "path_data_clean = root_path + \"data/clean/\"\n",
    "path_model = root_path + 'models/'\n",
    "features_path = root_path + 'data/features/'\n",
    "model_name = \"tfidf10000_svd1000\"\n",
    "path_model += model_name\n",
    "\n",
    "delete_old_model = True\n",
    "if delete_old_model:\n",
    "    try:\n",
    "        os.system(\"rm -rf \"+path_model)\n",
    "        os.system(\"mkdir \"+path_model)\n",
    "    except:\n",
    "        print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "falta agregar data v2 y beatiful soup para limpiar html en data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNoticias = pd.read_pickle(path_data_clean + \"/dfNoticiasCleanV2.p\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuerpo</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Hora</th>\n",
       "      <th>ID</th>\n",
       "      <th>Resumen</th>\n",
       "      <th>Seccion_1</th>\n",
       "      <th>Seccion_2</th>\n",
       "      <th>Seccion_3</th>\n",
       "      <th>Subtema_1</th>\n",
       "      <th>Subtema_2</th>\n",
       "      <th>Subtema_3</th>\n",
       "      <th>Tema_1</th>\n",
       "      <th>Tema_2</th>\n",
       "      <th>Tema_3</th>\n",
       "      <th>Titular</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nMarcel Granollers (44°) sorprendió a David F...</td>\n",
       "      <td>20140929</td>\n",
       "      <td>09:57</td>\n",
       "      <td>20140929095927</td>\n",
       "      <td>\\nEl español cayó ante su compatriota Marcel G...</td>\n",
       "      <td>deportes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>torneos atp</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tenis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\nDavid Ferrer sufrió otra temprana eliminación\\n</td>\n",
       "      <td>fid_noticia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nEl Gobierno de Barack Obama ha enviado cuatr...</td>\n",
       "      <td>20140929</td>\n",
       "      <td>07:03</td>\n",
       "      <td>20140929065051</td>\n",
       "      <td>\\nLas conversaciones comenzaron el año 2010 y ...</td>\n",
       "      <td>pais</td>\n",
       "      <td>mundo</td>\n",
       "      <td>mundo</td>\n",
       "      <td>eeuu</td>\n",
       "      <td>relaciones exteriores</td>\n",
       "      <td>None</td>\n",
       "      <td>relaciones exteriores</td>\n",
       "      <td>eeuu</td>\n",
       "      <td>cuba</td>\n",
       "      <td>\\nObama ha enviado cuatro solicitudes a Chile ...</td>\n",
       "      <td>fid_noticia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nEste miércoles la Comisión Asesora Presidenc...</td>\n",
       "      <td>20140929</td>\n",
       "      <td>11:37</td>\n",
       "      <td>20140929105234</td>\n",
       "      <td>\\nRepresentantes del sector privado acusaron q...</td>\n",
       "      <td>pais</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>isapre</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>salud</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\nQuiebre en comisión presidencial de isapres ...</td>\n",
       "      <td>fid_noticia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nWolfgang Burmann, del Team Avanti, se adjudi...</td>\n",
       "      <td>20140929</td>\n",
       "      <td>10:05</td>\n",
       "      <td>20140929100825</td>\n",
       "      <td>\\nEl pedalero del equipo Avanti terminó en el ...</td>\n",
       "      <td>deportes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>chilenos</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ciclismo</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\nWolfgang Burmann ganó el segundo clasificato...</td>\n",
       "      <td>fid_noticia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nEl Gobierno, a través de Sernapesca, present...</td>\n",
       "      <td>20140929</td>\n",
       "      <td>15:47</td>\n",
       "      <td>20140929152501</td>\n",
       "      <td>\\nBachelet instruyó a los ministros de Economí...</td>\n",
       "      <td>pais</td>\n",
       "      <td>pais</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>medioambiente</td>\n",
       "      <td>region de valparaiso</td>\n",
       "      <td>None</td>\n",
       "      <td>\\nGobierno presentó querella por derrame de pe...</td>\n",
       "      <td>fid_noticia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Cuerpo     Fecha   Hora  \\\n",
       "1  \\nMarcel Granollers (44°) sorprendió a David F...  20140929  09:57   \n",
       "2  \\nEl Gobierno de Barack Obama ha enviado cuatr...  20140929  07:03   \n",
       "3  \\nEste miércoles la Comisión Asesora Presidenc...  20140929  11:37   \n",
       "4  \\nWolfgang Burmann, del Team Avanti, se adjudi...  20140929  10:05   \n",
       "6  \\nEl Gobierno, a través de Sernapesca, present...  20140929  15:47   \n",
       "\n",
       "               ID                                            Resumen  \\\n",
       "1  20140929095927  \\nEl español cayó ante su compatriota Marcel G...   \n",
       "2  20140929065051  \\nLas conversaciones comenzaron el año 2010 y ...   \n",
       "3  20140929105234  \\nRepresentantes del sector privado acusaron q...   \n",
       "4  20140929100825  \\nEl pedalero del equipo Avanti terminó en el ...   \n",
       "6  20140929152501  \\nBachelet instruyó a los ministros de Economí...   \n",
       "\n",
       "  Seccion_1 Seccion_2 Seccion_3    Subtema_1              Subtema_2 Subtema_3  \\\n",
       "1  deportes      None      None  torneos atp                   None      None   \n",
       "2      pais     mundo     mundo         eeuu  relaciones exteriores      None   \n",
       "3      pais      None      None       isapre                   None      None   \n",
       "4  deportes      None      None     chilenos                   None      None   \n",
       "6      pais      pais      None         None                   None      None   \n",
       "\n",
       "                  Tema_1                Tema_2 Tema_3  \\\n",
       "1                  tenis                  None   None   \n",
       "2  relaciones exteriores                  eeuu   cuba   \n",
       "3                  salud                  None   None   \n",
       "4               ciclismo                  None   None   \n",
       "6          medioambiente  region de valparaiso   None   \n",
       "\n",
       "                                             Titular         Type  \n",
       "1  \\nDavid Ferrer sufrió otra temprana eliminación\\n  fid_noticia  \n",
       "2  \\nObama ha enviado cuatro solicitudes a Chile ...  fid_noticia  \n",
       "3  \\nQuiebre en comisión presidencial de isapres ...  fid_noticia  \n",
       "4  \\nWolfgang Burmann ganó el segundo clasificato...  fid_noticia  \n",
       "6  \\nGobierno presentó querella por derrame de pe...  fid_noticia  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNoticias.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre procesing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_map = {}\n",
    "_map[\"Cuerpo\"] = []\n",
    "_map[\"Seccion\"] = []\n",
    "_map[\"Tema\"] = []\n",
    "_map[\"Subtema\"] = []\n",
    "\n",
    "count = 0\n",
    "for index, row in dfNoticias.iterrows():    \n",
    "    _map[\"Cuerpo\"].append(row[\"Cuerpo\"]) \n",
    "    _map[\"Seccion\"].append(row[\"Seccion_1\"])\n",
    "    _map[\"Tema\"].append(row[\"Tema_1\"])\n",
    "    _map[\"Subtema\"].append(row[\"Subtema_1\"])\n",
    "\n",
    "df = pd.DataFrame(_map)\n",
    "# Elimino clase corporativo, muy pocos ejemplos\n",
    "df = df[df.Seccion != \"corporativo\"]\n",
    "\n",
    "    \n",
    "X_untransformed = df['Cuerpo'].reset_index(drop=True)\n",
    "y1 = df['Seccion'].reset_index(drop=True)\n",
    "y2 = df['Tema'].reset_index(drop=True)\n",
    "y3 = df['Subtema'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraccion\n",
    "\n",
    "### Data representation\n",
    "* Normalisacion\n",
    "* TFID calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\" Funcion de normalizacion \"\"\"    \n",
    "    # split into words\n",
    "    tokens = nltk.tokenize.word_tokenize(text,language='spanish', preserve_line=False)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]    \n",
    "    \n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    # remove remaining tokens that are n<<<<<<<<<<<<<<<<<<<<<\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    \n",
    "    # stop word and remove accent\n",
    "    def strip_accents(s):\n",
    "        return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "    stop_words = set(spanish_stopwords)\n",
    "    words = [strip_accents(w) for w in words if not w in stop_words]\n",
    "    return u\" \".join(words)\n",
    "    \n",
    "#     stemmer = SnowballStemmer(\"spanish\")\n",
    "#     out = \"\"\n",
    "#     for word in words:\n",
    "#         out += stemmer.stem(word)+\" \"    \n",
    "#     return out\n",
    "\n",
    "\n",
    "\n",
    "# spanish_stopwords = stopwords.words('spanish')\n",
    "# def normalize_text(text):\n",
    "#     return u\" \".join([x for x in [y for y in text.lower().strip().split(\" \")] \n",
    "#                       if len(x) > 1 and x not in spanish_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Marcel Granollers (44°) sorprendió a David Ferrer (5°), segundo cabeza de serie, en duelo español de la primera ronda del torneo de Tokio, Japón, al vencerlo por 4-6, 6-4 y 6-4 en dos horas y ocho minutos.\n",
      "Es la primera vez en seis encuentros que Granollers, finalista en Casablanca en abril, consigue, no solo ganarle un set al actual cinco del mundo en toda su vida, si no también la victoria 150 de su carrera, que le coloca en segunda ronda contra el estadounidense Steve Johnson.\n",
      "Ferrer, que se separó recientemente de su entrenador José Francisco Altur, señaló que se despistó en el segundo parcial. \"Perdí mi concentración en el segundo set. No estoy jugando bien últimamente y he encajado varios malos resultados\", admitió.\n",
      "Tras caer en la final del Masters 1.000 de Cincinnati ante el suizo Roger Federer (3°), el tenista de Javea cedió ante el francés Gilles Simon (37°) en la tercera ronda del US Open, y luego en la segunda en Shenzen (China), contra el serbio Victor Troicki (152°). En total ha ganado en lo que va de temporada 44 partidos y ha perdido 19.\n",
      "Esta última derrota, complica su objetivo de ganar uno de los cinco puestos que quedan aún libres para el Masters de Londres, aunque tiene todavía opciones en los dos Masters 1.000 que quedan Shanghai la próxima semana y luego en París-Bercy, y en medio en el ATP 500 de Valencia.\n",
      "En Tokio puede tener su oportunidad el suizo Stan Wawrinka (4°), primer favorito, que con alcanzar la final se aseguraría su presencia en el O2 londinense por segundo año consecutivo.\n",
      "Resultados de primera ronda\n",
      "Marcel Granollers (ESP) a David Ferrer (ESP), 4-6 6-4 y 6-4\n",
      "Jack Sock (EE.UU.) a Aleksandr Dolgopolov (UCR) 6-4 y 6-1\n",
      "Kevin Anderson (SUD) a Dominique Thiem (AUT) 7-6 (5) y 6-4\n",
      "Gilles Muller (LUX) a Federico Delbonis (ARG) 6-3 y 6-4\n",
      "Andrey Golubev (KAZ) a Pierre-Hugues Herbert (FRA) 6-4 y 6-4\n",
      "Steve Johnson (EE.UU.) a Hiroki Moriya (JPN), 7-6 (4) y 6-2. \n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "Normalize text\n",
      "Extract wordbags\n",
      "TFIDF end time :71.80487704277039\n",
      "Number of features: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "print(\"start\")\n",
    "\n",
    "\n",
    "X_untransformed = X_untransformed\n",
    "n_docs = X_untransformed.shape[0]\n",
    "n_cpu = 40\n",
    "\n",
    "batch_size = int(n_docs/n_cpu)\n",
    "\n",
    "#'log', \"idf\":50.0\n",
    "\n",
    "wb = wordbatch.WordBatch(normalize_text, \n",
    "                         extractor=(WordBag, {\"hash_ngrams\": 1, \"hash_ngrams_weights\": [1.0, 1.0],\n",
    "                                              \"hash_size\": 2**28, \"norm\": \"l2\", \"tf\": 1.0,\n",
    "                                              \"idf\": 1.0}), procs=n_cpu, n_words=10000, minibatch_size=batch_size)\n",
    "                                              #\"idf\": 1.0}), procs=n_cpu, n_words=1000, minibatch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# wb = wordbatch.WordBatch(normalize_text, \n",
    "#                          extractor=(WordBag, {\"hash_ngrams\": 2, \"hash_ngrams_weights\": [1.0, 1.0],\n",
    "#                                               \"hash_size\": 2**28, \"norm\": \"l2\", \"tf\": 1.0,\n",
    "#                                               \"idf\": 1.0}), procs=n_cpu, n_words=10000, minibatch_size=batch_size)\n",
    "\n",
    "# add method=\"serial\" to extractor for debug normalize function\n",
    "\n",
    "wb.dictionary_freeze = True\n",
    "X_transformed_zero = wb.fit_transform(list(X_untransformed),reset= False)\n",
    "\n",
    "non_zero_index_feat = np.array(np.clip(X_transformed_zero.getnnz(axis=0) - 1, 0, 1), dtype = bool)\n",
    "X_transformed = X_transformed_zero[:, non_zero_index_feat]\n",
    "\n",
    "print(\"TFIDF end time :\" + str(time.time() - start) )\n",
    "\n",
    "X = X_transformed\n",
    "\n",
    "#X = X.todense()\n",
    "print('Number of features: {}'.format(X.shape[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "\n",
    "Dim redution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end time :82.43752145767212\n"
     ]
    }
   ],
   "source": [
    "svd_enable = True\n",
    "new_dim = 1000\n",
    "\n",
    "\n",
    "if svd_enable :\n",
    "    start = time.time()\n",
    "    svdT = TruncatedSVD(n_components = new_dim)\n",
    "    X = svdT.fit_transform(X)\n",
    "    print(\"end time :\" + str(time.time() - start) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data\n",
    "\n",
    "### save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_features = True \n",
    "split_data = False\n",
    "file_name = \"tfid_hash28_n10000_svd1000_sin_stemmig.p\"\n",
    "train_fraction = 0.8\n",
    "\n",
    "if split_data and save_features :\n",
    "    y1 = y1.values    \n",
    "\n",
    "    np.random.seed(42)\n",
    "    train_indices = np.random.choice(X.shape[0], round(train_fraction*X.shape[0]), replace=False)\n",
    "    test_indices = np.array(list(set(range(X.shape[0])) - set(train_indices)))\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y1[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_test = y1[test_indices]\n",
    "    features_path_ = features_path + \"dataTrainTest_\" + file_name\n",
    "    pickle.dump( (X_train,y_train,X_test,y_test) , open( features_path_, \"wb\" ) )\n",
    "elif save_features:\n",
    "    features_path_ = features_path + \"dataV2_\" + file_name\n",
    "    pickle.dump( (X,y1,y2,y3) , open( features_path_, \"wb\" ) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save models\n",
    "* wordabatch calculator\n",
    "* svd transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"tfid_hash28_n10000_svd1000_sin_stemmig.p\"\n",
    "features_path_ = features_path + \"calcFeat_dataV2_\" + file_name\n",
    "pickle.dump( (wb,svdT,non_zero_index_feat), open( features_path_, \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
